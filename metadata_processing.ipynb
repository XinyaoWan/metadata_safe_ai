{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from dateutil import parser\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "for img_id in [f\"{i:06d}\" for i in range(100000)]:\n",
    "    fp = f\"infos/single_frames/{img_id}/metadata.json\"\n",
    "    with open(fp, \"r\") as file:\n",
    "        metadata[img_id] = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format into dataframe first\n",
    "keys = [\"frame_id\", \"time\", \"country_code\", \"scraped_weather\", \"road_type\", \"road_condition\", \"time_of_day\", \"num_vehicles\", \"longitude\", \"latitude\", \"solar_angle_elevation\"]\n",
    "rows = []\n",
    "for _, item in metadata.items():\n",
    "    row = []\n",
    "    for key in keys:\n",
    "        row.append(item[key])\n",
    "    rows.append(row)\n",
    "\n",
    "metadata_df = pd.DataFrame(rows, columns=keys)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Start a new dataframe to hold the converted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_converted_df = pd.DataFrame()\n",
    "metadata_converted_df[\"image_id\"] = metadata_df[\"frame_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convert time from ISO 8601 format to Unix time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iso_to_unix(iso_str):\n",
    "    dt = parser.isoparse(iso_str)  # Parse ISO 8601 format\n",
    "    unix_timestamp = dt.timestamp()  # Convert to Unix time (float)\n",
    "    return unix_timestamp\n",
    "\n",
    "# Perform conversion on the \"time\" column\n",
    "metadata_converted_df[\"time\"] = metadata_df[\"time\"].apply(iso_to_unix)\n",
    "\n",
    "metadata_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert country_code to numerical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_converted_df[\"country_code\"], encoding_cc = pd.factorize(metadata_df[\"country_code\"])\n",
    "\n",
    "metadata_converted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Category Mapping:\", dict(enumerate(encoding_cc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert scraped_weather to numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata_df[\"scraped_weather\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A mannual encoding is performed here, with the following rationale:\n",
    "- 0 = Clear-day: Ideal lighting, no obstructions.\n",
    "- 1 = Clear-night: Less ideal than daytime due to reduced lighting, but still clear.\n",
    "- 2 = Partly-cloudy-day: Slightly reduced contrast, but mostly clear.\n",
    "- 3 = Partly-cloudy-night: Similar to clear-night but with clouds reducing moonlight.\n",
    "- 4 = Cloudy: Diffused lighting, lower contrast but no major obstructions.\n",
    "- 5 = Wind: Motion blur can be an issue, especially for lightweight objects.\n",
    "- 6 = Rain: Water droplets on the lens, reflections, and reduced visibility.\n",
    "- 7 = Snow: More occlusion than rain, with objects blending into the white background.\n",
    "- 8 = Fog: The most challenging: heavy occlusion, low contrast, and objects may be completely invisible.\n",
    "'''\n",
    "def weather_encoding(weather):\n",
    "    encoding = {\n",
    "        \"clear-day\": 0,\n",
    "        \"clear-night\": 1,\n",
    "        \"partly-cloudy-day\": 2,\n",
    "        \"partly-cloudy-night\": 3,\n",
    "        \"cloudy\": 4,\n",
    "        \"wind\": 5,\n",
    "        \"rain\": 6,\n",
    "        \"snow\": 7,\n",
    "        \"fog\": 8 \n",
    "    }\n",
    "\n",
    "    return encoding[weather]\n",
    "\n",
    "metadata_converted_df[\"weather\"] = metadata_df[\"scraped_weather\"].apply(weather_encoding)\n",
    "\n",
    "metadata_converted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_weather = {\n",
    "        0: \"clear-day\",\n",
    "        1: \"clear-night\",\n",
    "        2: \"partly-cloudy-day\",\n",
    "        3: \"partly-cloudy-night\",\n",
    "        4: \"cloudy\",\n",
    "        5: \"wind\",\n",
    "        6: \"rain\",\n",
    "        7: \"snow\",\n",
    "        8: \"fog\" \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert road type and road condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_converted_df[\"road_type\"], encoding_rt = pd.factorize(metadata_df[\"road_type\"])\n",
    "metadata_converted_df[\"road_condition\"], encoding_rc = pd.factorize(metadata_df[\"road_condition\"])\n",
    "\n",
    "metadata_converted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Category Mapping:\", dict(enumerate(encoding_rt)))\n",
    "print(\"Category Mapping:\", dict(enumerate(encoding_rc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Convert time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_converted_df[\"time_of_day\"], encoding_td = pd.factorize(metadata_df[\"time_of_day\"])\n",
    "\n",
    "metadata_converted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Category Mapping:\", dict(enumerate(encoding_td)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Copy the rest, which does not need conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_converted_df[\"num_vehicles\"] = metadata_df[\"num_vehicles\"]\n",
    "metadata_converted_df[\"longitude\"] = metadata_df[\"longitude\"]\n",
    "metadata_converted_df[\"latitude\"] = metadata_df[\"latitude\"]\n",
    "metadata_converted_df[\"solar_angle_elevation\"] = metadata_df[\"solar_angle_elevation\"]\n",
    "\n",
    "metadata_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Record the encoding schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_encoding_schema = {\n",
    "    \"country_code\": dict(enumerate(encoding_cc)),\n",
    "    \"weather\": encoding_weather,\n",
    "    \"time_of_day\": dict(enumerate(encoding_td)),\n",
    "    \"road_type\": dict(enumerate(encoding_rt)),\n",
    "    \"road_condition\": dict(enumerate(encoding_rc))\n",
    "}\n",
    "\n",
    "# same as a json file\n",
    "with open(\"outputs/metadata_encoding.json\", \"w\") as file:\n",
    "    json.dump(metadata_encoding_schema, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save the converted metadata to the corresponding folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = [1 + 5000 * i for i in range(10)]\n",
    "\n",
    "for start in starts:\n",
    "    end = start + 5000 - 1\n",
    "    target_imgs = pd.read_csv(\n",
    "        f\"outputs/{start}_{end}/predictions.csv\", usecols=[\"image_id\"], dtype=str\n",
    "    ).squeeze()\n",
    "\n",
    "    selector = metadata_converted_df[\"image_id\"].isin(target_imgs)\n",
    "\n",
    "    metadata_converted_df[selector].to_csv(\n",
    "        f\"outputs/{start}_{end}/metadata/metadata.csv\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calibration.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = {}\n",
    "for img_id in [f\"{i:06d}\" for i in range(100000)]:\n",
    "    fp = f\"infos/single_frames/{img_id}/calibration.json\"\n",
    "    with open(fp, \"r\") as file:\n",
    "        calibration[img_id] = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for img_id, calibration_img in calibration.items():\n",
    "    calibration_img = pd.json_normalize(calibration_img, sep='_')\n",
    "    calibration_img.insert(0, \"image_id\", img_id)\n",
    "    rows.append(calibration_img)\n",
    "\n",
    "calibration_df = pd.concat(rows, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Prepare a new dataframe for the converted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calibration_converted_df = pd.DataFrame()\n",
    "calibration_converted_df[\"image_id\"] = calibration_df[\"image_id\"]\n",
    "\n",
    "calibration_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract features from FC_intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explanation of camera intrinsics: https://ksimek.github.io/2013/08/13/intrinsic/\n",
    "\n",
    "The format of intrinsics:\n",
    "First row: fx, 0, cx, 0 (focal length in x, principal point x)\n",
    "Second row: 0, fy, cy, 0 (focal length in y, principal point y)\n",
    "Third row: 0, 0, 1, 0 (homogeneous coordinates)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extract_focal_length_x(matrix):\n",
    "    return matrix[0][0]\n",
    "\n",
    "\n",
    "def extract_focal_length_y(matrix):\n",
    "    return matrix[1][1]\n",
    "\n",
    "\n",
    "def extract_principle_point_x(matrix):\n",
    "    return matrix[0][2]\n",
    "\n",
    "\n",
    "def extract_principle_point_y(matrix):\n",
    "    return matrix[0][2]\n",
    "\n",
    "\n",
    "calibration_converted_df[\"focal_length_x\"] = calibration_df[\"FC_intrinsics\"].apply(\n",
    "    extract_focal_length_x\n",
    ")\n",
    "calibration_converted_df[\"focal_length_y\"] = calibration_df[\"FC_intrinsics\"].apply(\n",
    "    extract_focal_length_y\n",
    ")\n",
    "calibration_converted_df[\"principle_point_x\"] = calibration_df[\"FC_intrinsics\"].apply(\n",
    "    extract_principle_point_x\n",
    ")\n",
    "calibration_converted_df[\"principle_point_y\"] = calibration_df[\"FC_intrinsics\"].apply(\n",
    "    extract_principle_point_x\n",
    ")\n",
    "\n",
    "calibration_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract features from FC_extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Raw data:\n",
    "The first 3Ã—3 part represents the rotation matrix.\n",
    "The last column (first three rows) represents the translation vector (x, y, z) in meters.\n",
    "\n",
    "Conversion:\n",
    "1. Convert the rotation matrix to Euler angles: yaw, pitch, roll\n",
    "2. The translation vector directly gives the position of the camera in the world coordinate system.\n",
    "'''\n",
    "\n",
    "def extract_pose_x(matrix):\n",
    "    return matrix[0][-1]\n",
    "\n",
    "def extract_pose_y(matrix):\n",
    "    return matrix[1][-1]\n",
    "\n",
    "def extract_pose_z(matrix):\n",
    "    return matrix[2][-1]\n",
    "\n",
    "def extract_pose_yaw(matrix):\n",
    "    yaw = math.atan2(matrix[1][0], matrix[0][0])\n",
    "    return yaw\n",
    "\n",
    "def extract_pose_pitch(matrix):\n",
    "    pitch = math.asin(-matrix[2][0])\n",
    "    return pitch\n",
    "\n",
    "def extract_pose_roll(matrix):\n",
    "    roll = math.atan2(matrix[2][1], matrix[2][2])\n",
    "    return roll\n",
    "\n",
    "calibration_converted_df[\"camera_pose_x\"] = calibration_df[\"FC_extrinsics\"].apply(extract_pose_x)\n",
    "calibration_converted_df[\"camera_pose_y\"] = calibration_df[\"FC_extrinsics\"].apply(extract_pose_y)\n",
    "calibration_converted_df[\"camera_pose_z\"] = calibration_df[\"FC_extrinsics\"].apply(extract_pose_z)\n",
    "calibration_converted_df[\"camera_pose_yaw\"] = calibration_df[\"FC_extrinsics\"].apply(extract_pose_yaw)\n",
    "calibration_converted_df[\"camera_pose_pitch\"] = calibration_df[\"FC_extrinsics\"].apply(extract_pose_pitch)\n",
    "calibration_converted_df[\"camera_pose_roll\"] =  calibration_df[\"FC_extrinsics\"].apply(extract_pose_roll)\n",
    "\n",
    "calibration_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract features from FC_field_of_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The original format is: horizontal FOV, vertical FOV\n",
    "Simply flatten the data.\n",
    "'''\n",
    "calibration_converted_df[\"horizontal_fov\"] = calibration_df[\"FC_field_of_view\"].apply(lambda x: x[0])\n",
    "calibration_converted_df[\"vertical_fov\"] = calibration_df[\"FC_field_of_view\"].apply(lambda x: x[1])\n",
    "\n",
    "calibration_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save the converted calibrations to the corresponding folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = [1 + 5000 * i for i in range(10)]\n",
    "\n",
    "for start in starts:\n",
    "    end = start + 5000 - 1\n",
    "    target_imgs = pd.read_csv(\n",
    "        f\"outputs/{start}_{end}/predictions.csv\", usecols=[\"image_id\"], dtype=str\n",
    "    ).squeeze()\n",
    "\n",
    "    selector = calibration_converted_df[\"image_id\"].isin(target_imgs)\n",
    "\n",
    "    calibration_converted_df[selector].to_csv(\n",
    "        f\"outputs/{start}_{end}/metadata/calibration.csv\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ego_motion.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_motion = {}\n",
    "for img_id in [f\"{i:06d}\" for i in range(50000)]:\n",
    "    fp = f\"infos/single_frames/{img_id}/ego_motion.json\"\n",
    "    with open(fp, \"r\") as file:\n",
    "        ego_motion[img_id] = json.load(file)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"timestamps\", \"poses\", \"velocities\", \"accelerations\", \"angular_rates\"]\n",
    "rows = []\n",
    "for image_id, item in ego_motion.items():\n",
    "    row = [image_id]\n",
    "    for key in keys:\n",
    "        row.append(item[key])\n",
    "    rows.append(row)\n",
    "    \n",
    "ego_motion_df = pd.DataFrame(rows, columns=[\"image_id\"]+keys)\n",
    "ego_motion_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare a new dataframe for the converted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_motion_converted_df = pd.DataFrame()\n",
    "ego_motion_converted_df[\"image_id\"] = ego_motion_df[\"image_id\"]\n",
    "\n",
    "ego_motion_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the pose at the middle timestamp, and convert to x, y, z, yaw, pitch, and roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pose_x(matrices):\n",
    "    middle_idx = int(len(matrices) / 2)\n",
    "    matrix = matrices[middle_idx]\n",
    "    return matrix[0][-1]\n",
    "\n",
    "def extract_pose_y(matrices):\n",
    "    middle_idx = int(len(matrices) / 2)\n",
    "    matrix = matrices[middle_idx]\n",
    "    return matrix[1][-1]\n",
    "\n",
    "def extract_pose_z(matrices):\n",
    "    middle_idx = int(len(matrices) / 2)\n",
    "    matrix = matrices[middle_idx]\n",
    "    return matrix[2][-1]\n",
    "\n",
    "def extract_pose_yaw(matrices):\n",
    "    middle_idx = int(len(matrices) / 2)\n",
    "    matrix = matrices[middle_idx]\n",
    "    yaw = math.atan2(matrix[1][0], matrix[0][0])\n",
    "    return yaw\n",
    "\n",
    "def extract_pose_pitch(matrices):\n",
    "    middle_idx = int(len(matrices) / 2)\n",
    "    matrix = matrices[middle_idx]\n",
    "    pitch = math.asin(-matrix[2][0])\n",
    "    return pitch\n",
    "\n",
    "def extract_pose_roll(matrices):\n",
    "    middle_idx = int(len(matrices) / 2)\n",
    "    matrix = matrices[middle_idx]\n",
    "    roll = math.atan2(matrix[2][1], matrix[2][2])\n",
    "    return roll\n",
    "\n",
    "ego_motion_converted_df[\"ego_pose_x\"] = ego_motion_df[\"poses\"].apply(extract_pose_x)\n",
    "ego_motion_converted_df[\"ego_pose_y\"] = ego_motion_df[\"poses\"].apply(extract_pose_y)\n",
    "ego_motion_converted_df[\"ego_pose_z\"] = ego_motion_df[\"poses\"].apply(extract_pose_z)\n",
    "ego_motion_converted_df[\"ego_pose_yaw\"] = ego_motion_df[\"poses\"].apply(extract_pose_yaw)\n",
    "ego_motion_converted_df[\"ego_pose_pitch\"] = ego_motion_df[\"poses\"].apply(extract_pose_pitch)\n",
    "ego_motion_converted_df[\"ego_pose_roll\"] = ego_motion_df[\"poses\"].apply(extract_pose_roll)\n",
    "\n",
    "ego_motion_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Derive speed variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_speed_variance(velocities):\n",
    "    speeds = np.linalg.norm(velocities, axis=1)  # Compute speed magnitude\n",
    "    variance = np.var(speeds)  # Compute variance\n",
    "    return variance\n",
    "\n",
    "ego_motion_converted_df[\"speed_var\"] = ego_motion_df[\"velocities\"].apply(compute_speed_variance)\n",
    "\n",
    "ego_motion_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute jerk (rate of acceleration change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jerk(accelerations, timestamps):\n",
    "    accelerations = np.array(accelerations)\n",
    "    timestamps = np.array(timestamps)\n",
    "\n",
    "    dt = np.diff(timestamps)  # Time differences\n",
    "    da = np.diff(accelerations, axis=0)  # Acceleration differences\n",
    "\n",
    "    jerk = da / dt[:, np.newaxis]  # Compute jerk\n",
    "    return np.mean(jerk), np.max(jerk), np.std(jerk)\n",
    "\n",
    "\n",
    "jerk_ls = []\n",
    "\n",
    "for _, row in ego_motion_df.iterrows():\n",
    "    jerk = compute_jerk(row[\"accelerations\"], row[\"timestamps\"])\n",
    "    jerk_ls.append(jerk)\n",
    "\n",
    "\n",
    "ego_motion_converted_df[[\"mean_jerk\", \"max_jerk\", \"st_jerk\"]] = jerk_ls\n",
    "\n",
    "ego_motion_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Derive angular acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angular_acceleration(angular_rates, timestamps):\n",
    "    angular_rates = np.array(angular_rates)\n",
    "    timestamps = np.array(timestamps)\n",
    "\n",
    "    dt = np.diff(timestamps)  # Time differences\n",
    "    dw = np.diff(angular_rates, axis=0)  # Angular rate differences\n",
    "\n",
    "    angular_acceleration = dw / dt[:, np.newaxis]\n",
    "    return (\n",
    "        np.mean(angular_acceleration),\n",
    "        np.max(angular_acceleration),\n",
    "        np.std(angular_acceleration),\n",
    "    )\n",
    "\n",
    "\n",
    "angular_acc_ls = []\n",
    "\n",
    "for _, row in ego_motion_df.iterrows():\n",
    "    angular_acc = compute_angular_acceleration(row[\"angular_rates\"], row[\"timestamps\"])\n",
    "    angular_acc_ls.append(angular_acc)\n",
    "\n",
    "\n",
    "ego_motion_converted_df[[\"mean_angular_acc\", \"max_angular_acc\", \"st_angular_acc\"]] = (\n",
    "    angular_acc_ls\n",
    ")\n",
    "\n",
    "ego_motion_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compute lateral acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lateral_acceleration(velocities, angular_rates):\n",
    "    speeds = np.linalg.norm(velocities, axis=1)  # Compute speed magnitude\n",
    "    yaw_rates = np.array(angular_rates)[:, 2]  # Extract yaw rate (z-axis rotation)\n",
    "\n",
    "    lateral_acceleration = speeds * yaw_rates\n",
    "    return (\n",
    "        np.mean(lateral_acceleration),\n",
    "        np.max(lateral_acceleration),\n",
    "        np.std(lateral_acceleration),\n",
    "    )\n",
    "\n",
    "lateral_acc_ls = []\n",
    "\n",
    "for _, row in ego_motion_df.iterrows():\n",
    "    lateral_acc = compute_lateral_acceleration(row[\"velocities\"], row[\"angular_rates\"])\n",
    "    lateral_acc_ls.append(lateral_acc)\n",
    "\n",
    "\n",
    "ego_motion_converted_df[[\"mean_lateral_acc\", \"max_lateral_acc\", \"st_lateral_acc\"]] = (\n",
    "    lateral_acc_ls\n",
    ")\n",
    "\n",
    "ego_motion_converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the converted ego motion data to the corresponding folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = [1 + 5000 * i for i in range(10)]\n",
    "\n",
    "for start in starts:\n",
    "    end = start + 5000 - 1\n",
    "    target_imgs = pd.read_csv(\n",
    "        f\"outputs/{start}_{end}/predictions.csv\", usecols=[\"image_id\"], dtype=str\n",
    "    ).squeeze()\n",
    "\n",
    "    selector = ego_motion_converted_df[\"image_id\"].isin(target_imgs)\n",
    "\n",
    "    ego_motion_converted_df[selector].to_csv(\n",
    "        f\"outputs/{start}_{end}/metadata/ego_motion.csv\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Preparation (image paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: 1_5000\n",
      "Finished: 5001_10000\n",
      "Finished: 10001_15000\n",
      "Finished: 15001_20000\n",
      "Finished: 20001_25000\n",
      "Finished: 25001_30000\n",
      "Finished: 30001_35000\n",
      "Finished: 35001_40000\n",
      "Finished: 40001_45000\n",
      "Finished: 45001_50000\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    start = 5000 * i + 1\n",
    "    end = start + 5000 - 1\n",
    "\n",
    "    # Step 1: get image ids\n",
    "    image_ids = pd.read_csv(\n",
    "        f\"outputs/{start}_{end}/predictions.csv\",\n",
    "        usecols=[\"image_id\"],\n",
    "    )\n",
    "\n",
    "    image_ids = image_ids.drop_duplicates()\n",
    "    image_ids = image_ids.to_numpy()\n",
    "\n",
    "    image_ids = image_ids.flatten()\n",
    "\n",
    "    # Step 2: compose image paths\n",
    "    image_folders = [\n",
    "        f\"single_frames_img/{image_id:06d}/camera_front_blur\" for image_id in image_ids\n",
    "    ]\n",
    "    image_paths = [\n",
    "        os.path.join(image_folder, os.listdir(image_folder)[0])\n",
    "        for image_folder in image_folders\n",
    "    ]\n",
    "\n",
    "    # Step 3: calculate image features\n",
    "    rows = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        row = compute_image_features(image_path)\n",
    "        rows.append(row)\n",
    "\n",
    "    # Step 4: format results as a dataframe with image ids and image paths\n",
    "    image_feature_df = pd.DataFrame(rows)\n",
    "    image_feature_df[\"image_id\"] = image_ids\n",
    "    image_feature_df[\"image_path\"] = image_paths\n",
    "\n",
    "    image_feature_df.head()\n",
    "    image_feature_df.to_csv(f\"outputs/{start}_{end}/metadata/image_features.csv\", index=False)\n",
    "\n",
    "    print(f\"Finished: {start}_{end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Do KNN clustering to check if features are useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data_matrix, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on a matrix of numerical features.\n",
    "\n",
    "    Parameters:\n",
    "        data_matrix (np.ndarray): 2D array, shape (n_samples, n_features)\n",
    "        max_clusters (int): Maximum k to try for elbow method\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"labels\": array of cluster labels,\n",
    "            \"centers\": cluster centers,\n",
    "            \"optimal_k\": number of clusters chosen,\n",
    "            \"pca_variance_ratio\": variance captured by PCA axes\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Ensure numpy array\n",
    "    feature_names = data_matrix.columns\n",
    "    data = np.array(data_matrix)\n",
    "    assert data.ndim == 2, \"Input data must be a matrix (2D array).\"\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    # 1. Elbow Method for finding optimal number of clusters\n",
    "    inertias = []\n",
    "    for k in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(scaled_data)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot elbow curve\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(range(1, max_clusters + 1), inertias, marker=\"o\")\n",
    "    plt.title(\"Elbow Method For Optimal k\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Inertia (Within-Cluster SSE)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Choose optimal_k manually or use heuristic (elbow near sharp drop)\n",
    "    optimal_k = int(input(\"Enter optimal number of clusters (k) based on elbow plot: \"))\n",
    "\n",
    "    # 2. Fit KMeans with chosen k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    labels = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "    # 3. PCA for dimensionality reduction (to 2D)\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "    # Get the absolute value of the loadings\n",
    "    loadings = np.abs(pca.components_)  # shape: (n_components, n_features)\n",
    "\n",
    "    # Find the most influential feature for each component\n",
    "    most_important_feature = []\n",
    "    for i, component in enumerate(loadings):\n",
    "        most_important_idx = np.argmax(component)\n",
    "        most_important_feature.append(feature_names[most_important_idx])\n",
    "        print(f\"Principal Component {i + 1} is most influenced by: {most_important_feature[i]}\")\n",
    "\n",
    "    # 4. Visualization\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    scatter = plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap=\"tab10\", s=50)\n",
    "    plt.title(f\"K-Means Clustering (k={optimal_k}) - PCA Projection\")\n",
    "    plt.xlabel(most_important_feature[0])\n",
    "    plt.ylabel(most_important_feature[1])\n",
    "    plt.grid(True)\n",
    "    plt.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"labels\": labels,\n",
    "        \"centers\": kmeans.cluster_centers_,\n",
    "        \"optimal_k\": optimal_k,\n",
    "        \"pca_variance_ratio\": pca.explained_variance_ratio_\n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kmeans(image_feature_df.iloc[:, :-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to the original dataset and save again\n",
    "image_feature_df[\"cluster\"] = results[\"labels\"]\n",
    "\n",
    "image_feature_df.to_csv(\"outputs/1_5000/metadata/image_features_k6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check images by labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = image_feature_df[\"cluster\"] == 5\n",
    "image_cluster = image_feature_df[selector][\"image_path\"].to_list()\n",
    "\n",
    "navigate_images(image_cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
